# LogTCP

This repository is the basic implementation of our submission in TOSEM 2022: **Exploring Better Black-Box Test Case Prioritization via Log Analysis**. 

## Introduction
*LogTCP* is a general log-based black-box test case prioritization (BTCP) framework, which aims to mine test logs produced during test execution to more sufficiently reflect test behaviors, thereby improving the effectiveness of BTCP. Specifically, it includes three key components: log pre-processing, log representation, and test case prioritization. 

## Project Structure

The project is structured as follows:

```
LogTCP
.
├─ data/       # Scripts for the generation of log representation, e.g. the natural language pre-processing on log events, three strategies for log representation. 
├─ dataset/   
│  ├─ input/   # Input data.
│  ├─ process/ # Raw output data. This folder would be generated during the experiments execution.
├─ mutant/     # Scripts for mutant faults selection.
├─ prioritize/ # Scripts for test case prioritization strategies. 
├─ util/      
└─pipeline.py  # Main entrance code.
```

### Sample Input Data

To help better replicate the experiment, we provide a sample input data for the subject `Shiro-core`. In the directory `./dataset/input/shiro/core/`, many files with information about log parsing and mutant faults are placed.

```
./dataset/input/<project>/<module>
├─ drain_results/                # The log parsing results via Drain3.
│  ├─ all_line_event.txt         # The log event IDs for all logs.
│  ├─ log_events.txt             # The log events after log parsing.
├─ config.ini                    # The configuration data.
├─ mutant_id_2_test_case_id.txt  # The relationship between mutant faults and test cases.
├─ test_case.txt                 # All test cases in this module under test.
└─ test_case_event_list.txt      # The log-event sequence for each test case.
```

For ease of understanding, we explain each file in the directory  `./dataset/input/<project>/<module>`:

- `config.ini`: The configuration data,  i.e.,  the hyper-parameters in *FastText* and *Drain3* algorithms.
- `drain_results`: This folder is generated by log parsing tool *Drain3*.
  - `drain_results/all_line_event.txt`: The log event IDs for all logs entered in *Drain3*. It is used to collect the corpus to construct word vectors for the semantics-based log representation.
  - `drain_results/log_events.txt`: The log events parsed by *Drain3*. The log event IDs are assigned in the order of the log events in this file, starting from `0`.
- `test_case.txt`: All test cases in this module under test, including the test case without test execution logs. To assign test case ID, they were sorted in lexicographic order in advance. Likewise, the test case IDs start from `0`.
- `mutant_id_2_test_case_id.txt`: The `mutations.xml` file generated by the mutation tool *PIT* is too large, so we extract the relationship between mutant faults and test cases, and then obtain this file.  For each line, the first number is the mutant fault ID, and the other numbers are the test case IDs that killed it. 
- `test_case_2_event_sequence.txt`: The log-event sequence for each test case. For each line, the first token is the name of test case, and the others are the log event IDs for the test execution logs. 

Due to the general framework of our approach, as long as above information is constructed into the files in the `./dataset/input/<project>/<module>` folder according to the corresponding format, it is easy to apply LogTCP on such subjects. 

## Environment

Key Packages:

- fasttext
- numpy
- sklearn

## Experiment Replication

1. Prepare the data in the directory `./dataset/input/` according to the description [here](#Sample Input Data).

2. Execute the `prioritize.py` script with the following command:

```
python pipeline.py --project <project> --module <module> --logs_representation <logs_representation> --prioritization <prioritization> --distance_option <distance_option>
```

- The arguments `<project>` and `<module>` indicate the experimental subject.
- As for the argument  `<logs_representation>` , the possible values are `count`, `ordering`, and `semantics`, which indicate the count-based,  the ordering-based, and the semantics-based log representation, respectively.
- As for the argument  `<prioritization>` , the possible values are `arp`, `total`,  `additional` and `ideal`, which indicate the adaptive random prioritization strategy, the total strategy, the additional strategy, and the ideal strategy, respectively. It is worth noting that since the semantic-based representation strategy does not involve the concept of coverage, we cannot set  `<prioritization>`  to `total` or `additional`, but set  `<logs_representation>` to `semantics` at the same time.
- The argument `distance_option` indicates the distance calculation method between two log vectors, and it only takes effect when the argument  `<prioritization>` is set to `arp`. The possible values are `e`, `c`,  and `m`, which indicate the Euclidean distance, the manhattan distance, and the cosine distance, respectively. 


3. View the prioritization results stored in the folder `./dataset/process/<project>/<module>/priortiza_results/`.
   
    